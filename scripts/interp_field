#!/usr/bin/env python
""" Interpolate 3D CESM output using a specified field as an auxiliary vertical
coordinate.

This routine doesn't check for monotonicity of the coordinate; it's possible
(and very likely) that it will fail if or give unpredictable answers if you
specify a coordinate whose gradient changes sign with height. However, it
should be extremely useful for interpolating against geopotential height in the
atmosphere, or when there is an explicit pressure field already described
in the dataset.

To interpolate the default CESM hybrid-pressure coordinate to discrete pressure
levels, use the alternative script `interp_pres`.

"""
import logging
logging.basicConfig(level=logging.INFO, format="%(message)s")
logger = logging.getLogger()

import os
import sys
import darpy as dr
import numpy as np
import pandas as pd
import xarray as xr

from argparse import ArgumentParser, RawDescriptionHelpFormatter
parser = ArgumentParser(description=__doc__,
                        formatter_class=RawDescriptionHelpFormatter)
parser.add_argument("field", type=str,
                    help="Name of interpolation field")
parser.add_argument("in_fn", metavar="in.nc", type=str,
                    help="Name of input file")
parser.add_argument("out_fn", metavar="out.nc", type=str,
                    help="Name of output file")
parser.add_argument("-f", "--f-interp", type=str,
                    help="Optional, auxiliary file containing interpolation field")
parser.add_argument("--levels", nargs="+", type=float, required=True,
                    help="Interpolation levels, matching the units of the named"
                         " interpolation field")
parser.add_argument("--fields", nargs="+", type=str,
                    help="3D fields to interpolate; if not included, will interpolate"
                         " all available 3D fields.")
parser.add_argument("--classic", action="store_true",
                    help="Save in netCDF3 classic format")
parser.add_argument("--debug", action='store_true',
                    help="Enable debug logging")
parser.add_argument("-O", "--overwrite", action="store_true",
                    help="Overwrite existing output file, if any")

if __name__ == "__main__":

    args = parser.parse_args()

    if args.debug:
        logger.setLevel(logging.DEBUG)
        logger.debug("Debug logging enabled")

    # Load in the dataset
    logger.debug("Reading {}".format(args.in_fn))
    ds = xr.open_dataset(args.in_fn, decode_times=False, decode_cf=False)
    if args.f_interp:
        logger.debug("Reading {}".format(args.f_interp))
        ds_interp = xr.open_dataset(args.f_interp, decode_times=False, decode_cf=False)
        if args.field not in ds_interp:
            raise ValueError("Interpolation field ({}) not found in ({})"
                             .format(args.field, args.f_interp))
        interp_field_dims = ds_interp[args.field].dims
        interpolation_field = ds_interp[args.field]
    else:
        if args.field not in ds:
            raise ValueError("Interpolation field ({}) not found in ({})"
                             .format(args.field, args.f_interp))
        interp_field_dims = ds[args.field].dims
        interpolation_field = ds[args.field]

    # Look up fields to process
    fields_to_process = []
    if not args.fields:
        logger.debug("Reading all fields to find interpolants...")
        for v in ds.data_vars:
            if v == args.field:
                logger.debug("   skipping interpolation field ({})".format(
                    args.field
                ))
                continue

            if ds[v].dims == interp_field_dims:
                logger.debug("   adding field ({})".format(v))
                fields_to_process.append(v)
    else:
        fields_to_process = args.fields

    # Perform interpolation on variables
    interp_das = {}
    logger.debug("Interpolating...")
    for field in fields_to_process:
        logger.debug("    " + field)
        interpolation_levels = args.levels
        interped_field = dr.interp_by_field(ds[field],
                                            interpolation_field,
                                            interpolation_levels)

        # Copy attrs and set missing value attrs for CDO/NCO/etc
        interped_field.attrs['_FillValue'] = np.nan
        # interped_field.attrs['missing_value'] = np.nan

        dr.copy_attrs(ds[field], interped_field)
        interp_das[field] = interped_field

    # Combine into new DataSet
    logger.debug("Combining...")
    new_ds = xr.Dataset(interp_das, attrs=ds.attrs)

    # Correct CF-compliant vertical dimensions
    new_ds['lev'].attrs['units'] = ds[field].attrs['units']
    for key in ['standard_name', 'formula', 'positive']:
        if key in new_ds['lev'].attrs:
            del new_ds['lev'].attrs[key]

    # Append history
    call_str = __file__ + " ".join(sys.argv[1:])
    new_ds = dr.append_history(new_ds, call_str)

    # Save output file
    logger.debug("Writing output to {}".format(args.out_fn))

    # File overwritten check
    if os.path.exists(args.out_fn) and (not args.overwrite):
        while True:
            m = input("File '{}' exists; (o)verwrite or attempt to (a)ppend? "
                      .format(args.out_fn))
            if m in ['o', 'a']:
                break
        if m == "o":
            m = 'w'  # convert to 'to_netcdf()' mode flag
    else:
        m = 'w'
    writer_kws = dict(mode=m)

    if args.classic:
        writer_kws['format'] = 'NETCDF3_CLASSIC'
        logger.debug("   Saving classic format")

    new_ds.to_netcdf(args.out_fn, **writer_kws)
